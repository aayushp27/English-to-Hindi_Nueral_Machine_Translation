{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv('Hindi_English_Truncated_Corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  politicians do not have permission to do what ...   \n",
       "1        ted         I'd like to tell you about one such child,   \n",
       "2  indic2012  This percentage is even greater than the perce...   \n",
       "3        ted  what we really mean is that they're bad at not...   \n",
       "4  indic2012  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['source']=='ted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(lines).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          63.0\n",
       "1          42.0\n",
       "2          61.0\n",
       "3          64.0\n",
       "4          55.0\n",
       "          ...  \n",
       "127602     89.0\n",
       "127603     25.0\n",
       "127604    188.0\n",
       "127605     65.0\n",
       "127606     77.0\n",
       "Name: english_sentence, Length: 127607, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines['english_sentence'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[~pd.isnull(lines['english_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=lines.sample(n=25000,random_state=42)\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "\n",
    "# Remove extra spaces\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
    "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...  \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END  \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END  \n",
       "74470                      START_ और यह खास गुब्बारा _END  \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in lines['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in lines['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14030"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17540"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...   \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END   \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END   \n",
       "74470                      START_ और यह खास गुब्बारा _END   \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "82040                    11                   16  \n",
       "85038                     2                    5  \n",
       "58018                     7                    8  \n",
       "74470                     4                    6  \n",
       "122330                   16                   20  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[lines['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=lines[lines['length_eng_sentence']<=20]\n",
    "lines=lines[lines['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24774, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src=max(lines['length_hin_sentence'])\n",
    "max_length_tar=max(lines['length_eng_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14030, 17540)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 #for zero padding\n",
    "num_encoder_tokens += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39869</th>\n",
       "      <td>ted</td>\n",
       "      <td>your call your call</td>\n",
       "      <td>START_ आपका चुनाव आपका चुनाव _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93962</th>\n",
       "      <td>ted</td>\n",
       "      <td>so where are all these coming from then</td>\n",
       "      <td>START_ तो कहाँ से आ रहे हैं यह _END</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23802</th>\n",
       "      <td>ted</td>\n",
       "      <td>where passengers on the ferry</td>\n",
       "      <td>START_ जहाँ फेरी के यात्रियों ने _END</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44557</th>\n",
       "      <td>ted</td>\n",
       "      <td>the early s i was in college</td>\n",
       "      <td>START_ सत्तर के दशक की शुरुवात में मैं कॉलेज म...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52961</th>\n",
       "      <td>ted</td>\n",
       "      <td>thats plato descartes nietzsche</td>\n",
       "      <td>START_ यह प्लेटो डेस्कर्टस निट्सचे _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40974</th>\n",
       "      <td>ted</td>\n",
       "      <td>ive spent my life</td>\n",
       "      <td>START_ मैं अपना जीवन बिताया है _END</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125566</th>\n",
       "      <td>ted</td>\n",
       "      <td>well it turns out you take each of the varieties</td>\n",
       "      <td>START_ तो तब आप पूर्णीमा की रात को की किस्में ...</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118875</th>\n",
       "      <td>ted</td>\n",
       "      <td>and you keep cutting it</td>\n",
       "      <td>START_ और इसे काटते जाइये। _END</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31077</th>\n",
       "      <td>ted</td>\n",
       "      <td>and in the process</td>\n",
       "      <td>START_ और इस प्रक्रिया में _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39155</th>\n",
       "      <td>ted</td>\n",
       "      <td>so you increase sexual potency</td>\n",
       "      <td>START_ इसलिए आपकी जननक्षमता बढती है । _END</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                  english_sentence  \\\n",
       "39869     ted                               your call your call   \n",
       "93962     ted           so where are all these coming from then   \n",
       "23802     ted                     where passengers on the ferry   \n",
       "44557     ted                      the early s i was in college   \n",
       "52961     ted                   thats plato descartes nietzsche   \n",
       "40974     ted                                 ive spent my life   \n",
       "125566    ted  well it turns out you take each of the varieties   \n",
       "118875    ted                           and you keep cutting it   \n",
       "31077     ted                                and in the process   \n",
       "39155     ted                    so you increase sexual potency   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "39869                   START_ आपका चुनाव आपका चुनाव _END   \n",
       "93962                 START_ तो कहाँ से आ रहे हैं यह _END   \n",
       "23802               START_ जहाँ फेरी के यात्रियों ने _END   \n",
       "44557   START_ सत्तर के दशक की शुरुवात में मैं कॉलेज म...   \n",
       "52961             START_ यह प्लेटो डेस्कर्टस निट्सचे _END   \n",
       "40974                 START_ मैं अपना जीवन बिताया है _END   \n",
       "125566  START_ तो तब आप पूर्णीमा की रात को की किस्में ...   \n",
       "118875                    START_ और इसे काटते जाइये। _END   \n",
       "31077                     START_ और इस प्रक्रिया में _END   \n",
       "39155          START_ इसलिए आपकी जननक्षमता बढती है । _END   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "39869                     4                    6  \n",
       "93962                     8                    9  \n",
       "23802                     5                    7  \n",
       "44557                     7                   12  \n",
       "52961                     4                    6  \n",
       "40974                     4                    7  \n",
       "125566                   10                   14  \n",
       "118875                    5                    6  \n",
       "31077                     4                    6  \n",
       "39155                     5                    8  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19819,), (4955,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder-Decoder Architecture\n",
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    4209300     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    5262300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 17541)  5279841     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,193,841\n",
      "Trainable params: 16,193,841\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "154/154 [==============================] - 292s 2s/step - loss: 2.9283 - val_loss: 2.8510\n",
      "Epoch 2/40\n",
      "154/154 [==============================] - 299s 2s/step - loss: 2.7174 - val_loss: 2.6970\n",
      "Epoch 3/40\n",
      "154/154 [==============================] - 297s 2s/step - loss: 2.5575 - val_loss: 2.6104\n",
      "Epoch 4/40\n",
      "154/154 [==============================] - 296s 2s/step - loss: 2.4462 - val_loss: 2.5653\n",
      "Epoch 5/40\n",
      "154/154 [==============================] - 296s 2s/step - loss: 2.3521 - val_loss: 2.5184\n",
      "Epoch 6/40\n",
      "154/154 [==============================] - 297s 2s/step - loss: 2.2668 - val_loss: 2.4991\n",
      "Epoch 7/40\n",
      "154/154 [==============================] - 298s 2s/step - loss: 2.1865 - val_loss: 2.4698\n",
      "Epoch 8/40\n",
      "154/154 [==============================] - 302s 2s/step - loss: 2.1124 - val_loss: 2.4698\n",
      "Epoch 9/40\n",
      "154/154 [==============================] - 299s 2s/step - loss: 2.0425 - val_loss: 2.4586\n",
      "Epoch 10/40\n",
      "154/154 [==============================] - 300s 2s/step - loss: 1.9728 - val_loss: 2.4537\n",
      "Epoch 11/40\n",
      "154/154 [==============================] - 302s 2s/step - loss: 1.9065 - val_loss: 2.4511\n",
      "Epoch 12/40\n",
      "154/154 [==============================] - 303s 2s/step - loss: 1.8420 - val_loss: 2.4550\n",
      "Epoch 13/40\n",
      "154/154 [==============================] - 303s 2s/step - loss: 1.7802 - val_loss: 2.4609\n",
      "Epoch 14/40\n",
      "154/154 [==============================] - 303s 2s/step - loss: 1.7176 - val_loss: 2.4644\n",
      "Epoch 15/40\n",
      "154/154 [==============================] - 307s 2s/step - loss: 1.6565 - val_loss: 2.4750\n",
      "Epoch 16/40\n",
      "154/154 [==============================] - 303s 2s/step - loss: 1.5985 - val_loss: 2.4871\n",
      "Epoch 17/40\n",
      "154/154 [==============================] - 302s 2s/step - loss: 1.5409 - val_loss: 2.5087\n",
      "Epoch 18/40\n",
      "154/154 [==============================] - 305s 2s/step - loss: 1.4844 - val_loss: 2.5211\n",
      "Epoch 19/40\n",
      "154/154 [==============================] - 316s 2s/step - loss: 1.4289 - val_loss: 2.5411\n",
      "Epoch 20/40\n",
      "154/154 [==============================] - 316s 2s/step - loss: 1.3746 - val_loss: 2.5619\n",
      "Epoch 21/40\n",
      "154/154 [==============================] - 306s 2s/step - loss: 1.3208 - val_loss: 2.5810\n",
      "Epoch 22/40\n",
      "154/154 [==============================] - 306s 2s/step - loss: 1.2709 - val_loss: 2.6025\n",
      "Epoch 23/40\n",
      "154/154 [==============================] - 306s 2s/step - loss: 1.2206 - val_loss: 2.6278\n",
      "Epoch 24/40\n",
      "154/154 [==============================] - 306s 2s/step - loss: 1.1718 - val_loss: 2.6446\n",
      "Epoch 25/40\n",
      "154/154 [==============================] - 306s 2s/step - loss: 1.1229 - val_loss: 2.6694\n",
      "Epoch 26/40\n",
      "154/154 [==============================] - 307s 2s/step - loss: 1.0755 - val_loss: 2.6924\n",
      "Epoch 27/40\n",
      "154/154 [==============================] - 310s 2s/step - loss: 1.0293 - val_loss: 2.7180\n",
      "Epoch 28/40\n",
      "154/154 [==============================] - 323s 2s/step - loss: 0.9870 - val_loss: 2.7363\n",
      "Epoch 29/40\n",
      "154/154 [==============================] - 328s 2s/step - loss: 0.9433 - val_loss: 2.7634\n",
      "Epoch 30/40\n",
      "154/154 [==============================] - 340s 2s/step - loss: 0.9009 - val_loss: 2.7832\n",
      "Epoch 31/40\n",
      "154/154 [==============================] - 343s 2s/step - loss: 0.8618 - val_loss: 2.7980\n",
      "Epoch 32/40\n",
      "154/154 [==============================] - 337s 2s/step - loss: 0.8239 - val_loss: 2.8272\n",
      "Epoch 33/40\n",
      "154/154 [==============================] - 312s 2s/step - loss: 0.7846 - val_loss: 2.8516\n",
      "Epoch 34/40\n",
      "154/154 [==============================] - 313s 2s/step - loss: 0.7489 - val_loss: 2.8754\n",
      "Epoch 35/40\n",
      "154/154 [==============================] - 313s 2s/step - loss: 0.7143 - val_loss: 2.9013\n",
      "Epoch 36/40\n",
      "154/154 [==============================] - 315s 2s/step - loss: 0.6804 - val_loss: 2.9233\n",
      "Epoch 37/40\n",
      "154/154 [==============================] - 308s 2s/step - loss: 0.6485 - val_loss: 2.9553\n",
      "Epoch 38/40\n",
      "154/154 [==============================] - 310s 2s/step - loss: 0.6182 - val_loss: 2.9762\n",
      "Epoch 39/40\n",
      "154/154 [==============================] - 307s 2s/step - loss: 0.5894 - val_loss: 2.9968\n",
      "Epoch 40/40\n",
      "154/154 [==============================] - 305s 2s/step - loss: 0.5610 - val_loss: 3.0214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2777ddfcd30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: let me act compassionately\n",
      "Actual Hindi Translation:  मुझे सहानुभूति पूर्ण और करुणामय व्यवहार करने दो \n",
      "Predicted Hindi Translation:  मैं सहानुभूति आखिर क्या चाहूँगा \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: that we pretend to protect\n",
      "Actual Hindi Translation:  जिसकी सुरक्षा का हम नाटक करते हैं \n",
      "Predicted Hindi Translation:  हम सुरक्षा के लिए हम कहते हैं \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: your knowledge is limited health is limited\n",
      "Actual Hindi Translation:  तुम्हारा ज्ञान सीमित हैस्वस्थ सीमित है \n",
      "Predicted Hindi Translation:  तुम्हारा नाम सीमित सीमित है और \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
